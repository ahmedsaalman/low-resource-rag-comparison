{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP7ArK5YQ7suRSuTpgRD+ip",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedsaalman/low-resource-rag-comparison/blob/main/Urdu_RAG_Final_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AeWXGawru7k6"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Environment Setup & Configuration\n",
        "# ==========================================\n",
        "# This cell installs all required libraries and mounts Google Drive.\n",
        "# It uses %%capture to keep the output clean for presentation.\n",
        "\n",
        "%%capture\n",
        "print(\"üöÄ Initializing the Urdu RAG Environment...\")\n",
        "\n",
        "# 1. Install Libraries\n",
        "# - transformers/bitsandbytes/accelerate: For running the Qwen LLM\n",
        "# - sentence-transformers/faiss-cpu: For the Retrieval system\n",
        "# - ipywidgets: For the interactive demo interface\n",
        "!pip install -q --upgrade transformers bitsandbytes accelerate sentence-transformers faiss-cpu ipywidgets\n",
        "\n",
        "# 2. Mount Google Drive\n",
        "# We need this to load your fine-tuned Dense Retriever and your Corpus file.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 3. Import Libraries\n",
        "import torch\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "import faiss\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 4. Define File Paths (Config)\n",
        "# These point to the files you created in your training notebook.\n",
        "DENSE_MODEL_PATH = \"/content/drive/MyDrive/models/urdu_dense_retriever_best\"\n",
        "CORPUS_PATH = \"/content/drive/MyDrive/data/urdu_covid_passages_min.jsonl\"\n",
        "GENERATOR_ID = \"Qwen/Qwen2.5-7B-Instruct\"  # We use the Base model as it performed best (85+ BLEU)\n",
        "\n",
        "print(\"‚úÖ Environment Ready! Proceed to Cell 2.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "_U9nWatux1QA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load Models, Build Index & Define Logic\n",
        "# ===============================================\n",
        "print(\"‚è≥ Loading RAG System... This may take 2-3 minutes.\")\n",
        "\n",
        "# --- PART A: Load the Retriever ---\n",
        "# We try to load your fine-tuned model. If missing, we fallback to the base model.\n",
        "if os.path.exists(DENSE_MODEL_PATH):\n",
        "    print(f\"   üìÇ Loading Fine-Tuned Retriever from: {DENSE_MODEL_PATH}\")\n",
        "    embedder = SentenceTransformer(DENSE_MODEL_PATH).to(\"cuda\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è Fine-tuned model not found. Loading Base Retriever (Fallback).\")\n",
        "    embedder = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\").to(\"cuda\")\n",
        "\n",
        "# --- PART B: Load Data & Build Index ---\n",
        "print(\"   üèóÔ∏è Building Search Index (FAISS)...\")\n",
        "corpus_texts = []\n",
        "corpus_ids = []\n",
        "\n",
        "# Check if corpus exists before loading\n",
        "if os.path.exists(CORPUS_PATH):\n",
        "    with open(CORPUS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            item = json.loads(line)\n",
        "            corpus_texts.append(item[\"text\"])\n",
        "            corpus_ids.append(item[\"id\"])\n",
        "\n",
        "    # Create embeddings for the search engine\n",
        "    passage_embeddings = embedder.encode(corpus_texts, convert_to_numpy=True, show_progress_bar=False)\n",
        "\n",
        "    # Initialize FAISS (Vector Database)\n",
        "    faiss.normalize_L2(passage_embeddings)\n",
        "    index = faiss.IndexFlatIP(passage_embeddings.shape[1])\n",
        "    index.add(passage_embeddings)\n",
        "    print(f\"      - Indexed {len(corpus_texts)} documents.\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"‚ùå Critical Error: Corpus file not found at {CORPUS_PATH}\")\n",
        "\n",
        "# --- PART C: Load the Generator (Qwen 2.5) ---\n",
        "print(f\"   üß† Loading Generator: {GENERATOR_ID} (4-bit)...\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(GENERATOR_ID)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    GENERATOR_ID, quantization_config=bnb_config, device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# --- PART D: Define the RAG Function ---\n",
        "def ask_ur_rag(query):\n",
        "    \"\"\"\n",
        "    1. Retrieve relevant docs using the Dense Retriever.\n",
        "    2. Format a prompt for the Qwen model.\n",
        "    3. Generate the answer in Urdu.\n",
        "    \"\"\"\n",
        "    # 1. Retrieval\n",
        "    q_emb = embedder.encode([query], convert_to_numpy=True)\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, 3) # Get Top 3 Documents\n",
        "\n",
        "    # Fetch text for the indices found\n",
        "    docs = [(corpus_ids[i], corpus_texts[i]) for idx, i in enumerate(I[0])]\n",
        "\n",
        "    # Create Context String\n",
        "    context = \"\\n\".join([f\"- {d[1]}\" for d in docs])\n",
        "\n",
        "    # 2. Prompt Engineering\n",
        "    sys_prompt = \"ÿ¢Ÿæ ÿß€å⁄© ŸÖÿß€Åÿ± ⁄àÿß⁄©Ÿπÿ± €Å€å⁄∫€î ŸÜ€å⁄Ü€í ÿØ€å ⁄Øÿ¶€å ŸÖÿπŸÑŸàŸÖÿßÿ™ ⁄©€å ÿ®ŸÜ€åÿßÿØ Ÿæÿ± ÿ≥ŸàÿßŸÑ ⁄©ÿß ÿßÿ±ÿØŸà ŸÖ€å⁄∫ ÿ¨Ÿàÿßÿ® ÿØ€å⁄∫€î\"\n",
        "    user_prompt = f\"ŸÖÿπŸÑŸàŸÖÿßÿ™:\\n{context}\\n\\nÿ≥ŸàÿßŸÑ: {query}\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": sys_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    # 3. Generation\n",
        "    text_input = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    model_inputs = tokenizer([text_input], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=256,\n",
        "            temperature=0.3, # Low temperature for factual consistency\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "    # Decode and clean response\n",
        "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    # Extract only the assistant's response (remove the prompt)\n",
        "    if \"assistant\" in response:\n",
        "        response = response.split(\"assistant\")[-1].strip()\n",
        "\n",
        "    return response, docs\n",
        "\n",
        "print(\"‚úÖ System Fully Operational! Ready for Demo.\")"
      ],
      "metadata": {
        "id": "9XNcR12fvEph",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "5d0430b716c542e0981dc6e113c2ac1f",
            "34f391eab1b746538bf74867faa3bd51",
            "ffd83eec29864285969cae95464756c7",
            "af11a1ef22dd45c090c83294a6a99dbc",
            "49da44bfd3c84fe685a72a5e7c30c7d6",
            "c6b681572c794d02b49af887f86b7f07",
            "72a0c584889a412fa328b53e48a2a14c",
            "3f84b9fdbfd047e0b76c9a715ff56653",
            "b4abb957f5e7459dbe8aa4e15f4d130b",
            "75e1784eb8ba456c82f6c46cb39ec316",
            "c2581f37d3834908b2a0890222f5b532",
            "c48bb23a2f3547cd8be52e9a892c34c0",
            "bf4ba0c9d06d42fba7eda9e65742bed2",
            "8f826e9244eb49a3b7aca74ab12c3a92",
            "e74898a236024cbaa070b9d6b6c0d702",
            "b6a4708422b3499a8f3642ebf564f009",
            "60a1de9d19a34965940cd72620a8c4f8",
            "4b9477582fce4646b9e86f7bd8a9aefd",
            "55bac4214171444aa1a2929b5e359938",
            "ea3a7d278fa84fb68bcee786a0bbfbef",
            "369a6b7a854d4c8bbab572dda7f0525a",
            "631f1d2bd57a4ac1bada9a4056394be5",
            "712df996c9e94039a28400321de46856",
            "8677aef3b7624545bc87d7fb37a71391",
            "b674b2e3984e40e9b0b703c1b5842b61",
            "cc6def0ff10e4ee1a5711ae029747648",
            "d2f1b51a8ffc417e90ae167bf3033503",
            "6a1c8fcfb2fc4f81b371713f25a1d66f",
            "f815ecc302b34bdaa6b311c431ab8f2d",
            "b8facb11c7e64476bd75645bc932861c",
            "320de03a2fd24c979a4edd03ab0512f2",
            "1e883810e91147f3a0d8e7d416785cdf",
            "cc654d279ee540d9adabb2824209cdc5",
            "85d68a8818cb44e8aa488adaf380592d",
            "246ae46268604f0989c28207a2148ed9",
            "9f779e81dbbf4e75a11aff1b551e23c4",
            "1b4a1694d3ed4e1cacd117c346401826",
            "8e4ce598f46e42579004bef7910a11d3",
            "9263b5381f4147e68e1a95d2700766fe",
            "d02786f9dab44fa2a8e283a7d689176b",
            "855e951276cc47be947f4264f55214a9",
            "cf5246a2cc264270b663d03f5379dbb2",
            "6090aa9da7744c289e4b525b85ef7dab",
            "1b79a7f5cb294c75b5191bbdb2a487bf",
            "56dd314af6f147b2b6e42dcbbfd0d235",
            "ecaf38ea9f8743479d058da79a7e755f",
            "4cba9676f95f41439ea831042785a6af",
            "e1383b251dc84c608da8f3ae8d4ee915",
            "91e23a09a80c421b852f00442b8a8989",
            "83c345469bfb430883c97636886e0132",
            "9921b71daa5340d89f80cd455f59b3fb",
            "8baa29c0d63740dea28121d9e6d0ee97",
            "f5333e54b151418abc77a816c4728fc6",
            "82ad83ecde45414db32172733e6ca764",
            "75e54b06d1f149579457483c87c6ccf9",
            "712ac59fb2a34ed09edb78c4d856f062",
            "0f31ec4dee244054b96138dd62766987",
            "23038e1920f546cc85e76d0646c0f0ce",
            "fdc6cc318eb846f7b56c41a716ea2265",
            "731388874c3f4404a9d7a99404f13aa9",
            "87892823dff44aed8223274d65d505d4",
            "817f55befcd9437296d3bb1df55d13ff",
            "7ae1c75214b5482bb93207e1841e3a04",
            "7afe4b1d4c2d444ea2bbc9595d22b797",
            "c92459b1d2bf4b70981ea85e2143748c",
            "8bf738f3a16240008bd7f5568c1b699e",
            "229ebaf2f9484ed8af29f0284207d164",
            "8b5f4bc6bedc4dbbba591844543c7d27",
            "27fa4511db5945e8ba6725723cf0b191",
            "392a8c1ec40c4a05abb8c6688e5a41f2",
            "a0fe3045a05b487e89a356c281a0fab0",
            "dfb84647c90e4fae958cfd68cd695d1b",
            "96d8adaf2a894567b5b44279b9698a97",
            "7d9e4beaedba4d62b972bb72d91c5aa2",
            "e06f2814295345d88f0e09779c60ebac",
            "fe3d709224734ee784b1bd538122bf69",
            "4a7f41e5a06f4aae91984c63a83fb7d4",
            "0638191f03ca4ebca24f8e3c8613b656",
            "03fe4f62b7d24aeba44741dcd2b0903e",
            "bf44e76938ea476ba51563a883914aec",
            "17fbdf42efa44c67a9117c6a3166dd72",
            "60fa258795dc438cb8bf67b2a32a6b1b",
            "e074ba1f82084c3b8f7785a7d36e422e",
            "7854eb60873245ef899b46860fa9d50a",
            "fa7250fb2e7d4186a10fc2182de7569b",
            "8a104118158f4557acd8636f73e42b50",
            "962cbef940674aad9946b669f66289d4",
            "6f5b1753a4e94dc4905adb9ff4f5232b",
            "903386c63bac479c88bba6f6bd36ab68",
            "55147062c34e4f22ae181f4868eb0e17",
            "d1f0e7decf1440eeb8274ddd0a1e23fd",
            "c75d3975c4004bed9c8104d9b21aa06d",
            "6631427d978f42878d7bfbde6779eba7",
            "ce7fe41677784ea680378900a35a72ad",
            "ec18bdcd469444b299366f771e4898e9",
            "e70cb4769ce249aa8887046c46b6200a",
            "ba40d719f14948e1ac9de10119f1e995",
            "108f343a6ded4295ae83bd46ff5deaeb",
            "9c48a41ee7954a0eb4a2669d51241196",
            "845882db2145497fbe7e78425a114c4a",
            "add835751e064c42a8cb59ad63d71372",
            "530bcd92dec14538b2c86ed2b8b4fe87",
            "3ff013484a104324b5fb381400476c7a",
            "a6541183306644e28c7b2110ae43d7bf",
            "81ce0c635ab1478095c4756311411e78",
            "9a8ef679825b40adbe23888de87700d9",
            "be8d2952dcb8463186d138ef9ef8e49d",
            "09c5433d154944ff9b8a9d995ac7af93",
            "e2cbfbc1777047e685febda3630668f6",
            "1cdc6f0f8ffc40849fc75a0e51830502",
            "e1ddab3439f148db97d85fa3057b192b",
            "29b9975a4e7a4672b7ec09ca151c9766",
            "fad23901b738445d91fb7eb9d8c69a81",
            "d73f6fdedf0044d983bec0f027ce8630",
            "670044503c714385aba04c12761ee0a7",
            "6e86a283f962491cb7be02486c3c672d",
            "8c24fde82af04b8eb83a830cf6b3bd85",
            "83fa8b75a4f3444fa82d49360d38f27a",
            "e739d3c6a85f48609d25f1394b966899",
            "a4ba832805cb43799edd767524f35cd7",
            "9ae2dd84df8147e6b99d18180bccb9b7",
            "2fc599caef954801916c75ecc0712a62",
            "42224911d5a4460d99efdf84763c80f8",
            "aee856866c774693920c37d399054d11",
            "d549e20961614464ae7f9e2595f2d8f6",
            "d7138aabd0c245c2bb4d706549ac3f91",
            "4369d505086744d79a89229b3eebc7a7",
            "df600e1f46bf422d8a9150fbfe517dea",
            "201c9de39e9845d1822a23fd10d7f4a3",
            "b9a90a8331174919a57634560aefc23e",
            "6dac2c2a145d45f2bd1b75714a031b99",
            "fb2ceb6950874b8bac3702b9ccb220ad",
            "66cf498fdc6e4ad8884ad5c27eda0d72",
            "a3c245dbff9b4eebba58ca79ff572e38",
            "46e04c62a1b04b90a38856442a1f2429",
            "510beed28b9d4adfa50081ecdf0b7c00",
            "213005afc8b94a0e9715203ac42396aa",
            "50ffd013127041b1bc52480ec1942b34",
            "d7619fa04b314847b4c7936d39a6ced6",
            "6a595e1428ad4ee890111d71e97c0587",
            "adcd44de43334e5e9d909c2d0068f8f5",
            "cc1f240c5c4f409f8073f42e56773ec9",
            "f5b8bc47075e4df08d4aac8cfd225800"
          ]
        },
        "outputId": "9eceb810-022e-4405-9a35-63259f886987"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Loading RAG System... This may take 2-3 minutes.\n",
            "   üìÇ Loading Fine-Tuned Retriever from: /content/drive/MyDrive/models/urdu_dense_retriever_best\n",
            "   üèóÔ∏è Building Search Index (FAISS)...\n",
            "      - Indexed 60 documents.\n",
            "   üß† Loading Generator: Qwen/Qwen2.5-7B-Instruct (4-bit)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d0430b716c542e0981dc6e113c2ac1f"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "631f1d2bd57a4ac1bada9a4056394be5"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc654d279ee540d9adabb2824209cdc5"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b79a7f5cb294c75b5191bbdb2a487bf"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75e54b06d1f149579457483c87c6ccf9"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bf738f3a16240008bd7f5568c1b699e"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a7f41e5a06f4aae91984c63a83fb7d4"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09c5433d154944ff9b8a9d995ac7af93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2cbfbc1777047e685febda3630668f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cdc6f0f8ffc40849fc75a0e51830502"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1ddab3439f148db97d85fa3057b192b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fc599caef954801916c75ecc0712a62"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5b8bc47075e4df08d4aac8cfd225800"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ System Fully Operational! Ready for Demo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 (Backup): Simple Text Loop\n",
        "# ================================\n",
        "print(\"ü©∫ Urdu COVID-19 AI Assistant (Simple Mode)\")\n",
        "print(\"Type 'exit' to stop.\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "while True:\n",
        "    print(\"\\nüëá ŸÜ€å⁄Ü€í ÿ≥ŸàÿßŸÑ ŸÑ⁄©⁄æ€å⁄∫ (Enter Question):\")\n",
        "    query = input() # Standard Python Input\n",
        "\n",
        "    if query.lower() in ['exit', 'quit', 'x']:\n",
        "        print(\"üëã Allah Hafiz!\")\n",
        "        break\n",
        "\n",
        "    if not query.strip(): continue\n",
        "\n",
        "    print(f\"\\nü§î Thinking...\")\n",
        "    try:\n",
        "        start = time.time()\n",
        "        ans, docs = ask_ur_rag(query)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*40)\n",
        "        print(f\"üì¢ ÿ¨Ÿàÿßÿ®: {ans}\")\n",
        "        print(\"=\"*40)\n",
        "        print(f\"üìö ÿ≠ŸàÿßŸÑ€Å: {docs[0][1][:100]}...\")\n",
        "        print(f\"‚è±Ô∏è Time: {time.time()-start:.2f}s\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ],
      "metadata": {
        "id": "ImvL8ZmAvBcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38dd2138-35e8-4c97-fe1e-ac1db2cabfe4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü©∫ Urdu COVID-19 AI Assistant (Simple Mode)\n",
            "Type 'exit' to stop.\n",
            "----------------------------------------\n",
            "\n",
            "üëá ŸÜ€å⁄Ü€í ÿ≥ŸàÿßŸÑ ŸÑ⁄©⁄æ€å⁄∫ (Enter Question):\n",
            "ÿ≥ŸÖÿßÿ¨€å ŸÅÿßÿµŸÑ€Å ÿ±⁄©⁄æŸÜ€í ⁄©€å ÿß€ÅŸÖ€åÿ™ ⁄©€åÿß €Å€íÿü\n",
            "\n",
            "ü§î Thinking...\n",
            "\n",
            "========================================\n",
            "üì¢ ÿ¨Ÿàÿßÿ®: ÿ≥ŸÖÿßÿ¨€å ŸÅÿßÿµŸÑ€Å ÿ±⁄©⁄æŸÜ€í ⁄©€å ÿß€ÅŸÖ€åÿ™ ÿ≤€åÿßÿØ€Å ÿ™ÿ± ÿßŸàÿ®€ÅÿØ€åŸÜ ÿßŸàÿ± ÿ≥ŸÑÿßŸÖÿ™ ⁄©€í ŸÑ€å€í €Å€í€î ÿßÿ≥€í ÿ±⁄©⁄æŸÜ€í ÿ≥€í ŸÖ€åŸπŸÜ⁄Øÿ≥ ⁄©€å ⁄©ŸÖ€å €ÅŸàÿ™€å €Å€íÿå ÿ¨ÿ≥ ÿ≥€í ÿ®⁄æ€å⁄ë ÿ®⁄æÿß⁄ë ŸàÿßŸÑ€å ÿ¨⁄Ø€ÅŸà⁄∫ ÿ≥€í ⁄Øÿ±€åÿ≤ €ÅŸàÿ™ÿß €Å€í€î ÿßÿ≥€í ÿ±⁄©⁄æŸÜ€í ÿ≥€í ⁄©⁄æŸÑ€å €ÅŸàÿß ŸÖ€å⁄∫ ŸàŸÇÿ™ ⁄Øÿ≤ÿßÿ±ŸÜÿß ÿßŸàÿ± Ÿà€åŸÜŸπ€åŸÑ€åÿ¥ŸÜ ⁄©€å ⁄©ŸÖ€å ⁄©€í ŸÖÿÆÿßÿ∑ÿ± ⁄©Ÿà ⁄©ŸÖ ⁄©ÿ±ÿ≥⁄©ÿ™ÿß €Å€í€î ÿßÿ≥€í ÿ±⁄©⁄æŸÜ€í ÿ≥€í Ÿàÿ®ÿßÿ¶€å ÿØŸàÿ± ŸÖ€å⁄∫ ÿßŸÜŸÅ€å⁄©ÿ¥ŸÜ ⁄©€í ÿßŸÖ⁄©ÿßŸÜÿßÿ™ ⁄©Ÿà ⁄©ŸÖ ⁄©ÿ±ÿ≥⁄©ÿ™ÿß €Å€í€î\n",
            "========================================\n",
            "üìö ÿ≠ŸàÿßŸÑ€Å: ÿ≥ŸÖÿßÿ¨€å ŸÅÿßÿµŸÑ€Å ÿ±⁄©⁄æŸÜÿß ÿßŸàÿ± ÿ®⁄æ€å⁄ë ÿ®⁄æÿß⁄ë ŸàÿßŸÑ€å ÿ¨⁄Ø€ÅŸà⁄∫ ÿ≥€í ⁄Øÿ±€åÿ≤ Ÿàÿ®ÿßÿ¶€å ÿØŸàÿ± ŸÖ€å⁄∫ ÿßŸÜŸÅ€å⁄©ÿ¥ŸÜ ⁄©€í ÿßŸÖ⁄©ÿßŸÜÿßÿ™ ⁄Ø⁄æŸπÿßÿ™ÿß €Å€íÿõ ⁄©⁄æŸÑ€å ...\n",
            "‚è±Ô∏è Time: 17.85s\n",
            "\n",
            "üëá ŸÜ€å⁄Ü€í ÿ≥ŸàÿßŸÑ ŸÑ⁄©⁄æ€å⁄∫ (Enter Question):\n",
            "⁄©ŸàŸà⁄à-19 ⁄©€å ÿ™ÿ¥ÿÆ€åÿµ ⁄©€í ŸÑ€å€í ⁄©ŸàŸÜ ÿ≥ÿß Ÿπ€åÿ≥Ÿπ ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ €ÅŸàÿ™ÿß €Å€íÿü\n",
            "\n",
            "ü§î Thinking...\n",
            "\n",
            "========================================\n",
            "üì¢ ÿ¨Ÿàÿßÿ®: ⁄©ŸàŸà⁄à-19 ⁄©€å ÿ™ÿ¥ÿÆ€åÿµ ⁄©€í ŸÑ€å€í ÿ±€åŸπ€å Ÿæÿ± ŸÖÿßÿ±⁄©ÿ± ÿ≥Ÿà€åÿ® Ÿπ€åÿ≥Ÿπ (rRT-PCR) ÿπÿßŸÖ ÿ∑Ÿàÿ± Ÿæÿ± ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ €ÅŸàÿ™ÿß €Å€í€î ÿßÿ≥ Ÿπ€åÿ≥Ÿπ ŸÜ€í Ÿàÿßÿ¶ÿ±ÿ≥ ⁄©€å ŸÖŸàÿ¨ŸàÿØ⁄Ø€å ⁄©€å ÿ™ÿµÿØ€åŸÇ ⁄©ÿ±ŸÜ€í ⁄©€å ŸÇÿßÿ®ŸÑ€åÿ™€î\n",
            "========================================\n",
            "üìö ÿ≠ŸàÿßŸÑ€Å: ⁄©ŸàŸà⁄à-19 ⁄©€å ÿ™ÿ¥ÿÆ€åÿµ ⁄©€í ŸÑ€å€í rRT-PCR ÿ≥Ÿà€åÿ® Ÿπ€åÿ≥Ÿπ ÿπÿßŸÖ ÿ∑Ÿàÿ± Ÿæÿ± ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ €ÅŸàÿ™€í €Å€å⁄∫ ÿßŸàÿ± €å€Å Ÿàÿßÿ¶ÿ±ÿ≥ ⁄©€å ŸÖŸàÿ¨ŸàÿØ⁄Ø€å ⁄©€å ÿ™ÿµÿØ...\n",
            "‚è±Ô∏è Time: 7.95s\n",
            "\n",
            "üëá ŸÜ€å⁄Ü€í ÿ≥ŸàÿßŸÑ ŸÑ⁄©⁄æ€å⁄∫ (Enter Question):\n",
            "⁄©ŸàŸà⁄à-19 Ÿà€å⁄©ÿ≥€åŸÜ ÿ¨ÿ≥ŸÖ ŸÖ€å⁄∫ ⁄©€åÿ≥€í ⁄©ÿßŸÖ ⁄©ÿ±ÿ™€å €Å€íÿü\n",
            "\n",
            "ü§î Thinking...\n",
            "\n",
            "========================================\n",
            "üì¢ ÿ¨Ÿàÿßÿ®: ⁄©ŸàŸà⁄à-19 Ÿà€å⁄©ÿ≥€åŸÜ ÿ¨ÿ≥ŸÖ ŸÖ€å⁄∫ ⁄©ÿßŸÖ ⁄©ÿ±ÿ™€å €Å€í ⁄©€Å Ÿà€å⁄©ÿ≥€åŸÜ ⁄©Ÿà Ÿàÿ±€åÿØ€åÿß⁄∫ ÿ≥€í Ÿàÿ±€ÅŸÜ€í ŸÑ⁄Øÿ™€å €Å€í ÿ¨€Åÿß⁄∫ ÿßÿ≥ ŸÜ€í ⁄©ŸàŸà⁄à-19 ⁄©€í ŸÖ€åŸπŸàÿ¶€í (ŸÖ€åŸπŸàÿ¶€í ⁄©€å €å⁄© ŸÜŸàÿπ) ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÑ ⁄©ÿ± ÿß€å⁄© ÿßŸÅÿ≥Ÿàÿ≥€åÿ¥ŸÜ (ÿ≠€åÿßÿ™€å ⁄©ÿ±ŸàŸÜÿß ŸÅ€åÿ±Ÿàÿ≥ ⁄©€í ŸÜÿ≥ÿÆ€Å) ÿ®ŸÜÿßÿ™€å €Å€í€î ÿßÿ≥ ÿßŸÅÿ≥Ÿàÿ≥€åÿ¥ŸÜ ⁄©€í ÿ∞ÿ±€åÿπ€í ÿ¨ÿ≥ŸÖÿßŸÜ€å ŸÜÿ∏ÿßŸÖ ⁄©Ÿà ⁄©ŸàŸà⁄à-19 ŸÅ€åÿ±Ÿàÿ≥ ⁄©€í Ÿàÿ¨ŸàÿØ ⁄©€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿØ€å ÿ¨ÿßÿ™€å €Å€í ŸÑ€å⁄©ŸÜ ŸÅ€åÿ±Ÿàÿ≥ ⁄©€å Ÿàÿ≥€åÿπ ⁄Øÿ≥ÿ™ÿ±ÿ¥ ⁄©€å ⁄Øÿ¶€å ŸÜ€Å€å⁄∫€î ÿßÿ≥ ⁄©€í ÿ®ÿπÿØ ÿ¨ÿ≥ŸÖ ⁄©ÿß ÿß€å⁄© ÿ≠ŸÅÿßÿ∏ÿ™€å ÿ±ÿØÿπŸÖŸÑ Ÿæ€åÿØÿß €ÅŸàÿ™ÿß €Å€í ÿ¨ÿ≥ ŸÜ€í ⁄©ŸàŸà⁄à-19 ŸÅ€å\n",
            "========================================\n",
            "üìö ÿ≠ŸàÿßŸÑ€Å: Ÿà€å⁄©ÿ≥€åŸÜ€å⁄∫ ⁄©ŸàŸà⁄à-19 ⁄©€í ÿÆŸÑÿßŸÅ ÿ≠ŸÅÿßÿ∏ÿ™€å ÿ±ÿØÿπŸÖŸÑ Ÿæ€åÿØÿß ⁄©ÿ±ÿ™€å €Å€å⁄∫ ÿßŸàÿ± ÿ¥ÿØ€åÿØ ÿ®€åŸÖÿßÿ±€å ÿßŸàÿ± ÿßŸÖŸàÿßÿ™ ⁄©€í ÿÆÿ∑ÿ±€í ⁄©Ÿà ⁄©ŸÖ ⁄©ÿ±ÿ™€å €Å€å⁄∫...\n",
            "‚è±Ô∏è Time: 20.19s\n",
            "\n",
            "üëá ŸÜ€å⁄Ü€í ÿ≥ŸàÿßŸÑ ŸÑ⁄©⁄æ€å⁄∫ (Enter Question):\n",
            "exit\n",
            "üëã Allah Hafiz!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "_f-4TFg4JSik"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "rM2uyo5dJSim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "h63djNmNJSim"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "IP9d2KSh2MBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "nKndhxiuxp-T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
